开发日记-IMGP 
========================
> 图片解码播放器ImagePlayer

* 开发板：s5pv210 cortex-A8
* 运行环境：内核2.6.35

[TOC]

###2017-2-9

环境搭建和基础环境确认:

(1)uboot<br>
(2)kernel(配置成支持nfs)<br>
(3)rootfs<br>
(4)主机ubuntu中tftp服务器<br>
(5)主机ubuntu中nfs服务器

工程建立：

Makefile和Makefile.build


###2017-2-10

####framebuffer基本操作代码

**错误1**：

    built-in.o: In function `main':
    /root/winshare/ImagePlayer/main.c:17: undefined reference to `fb_open'

但是明明有定义啊？不是这个原因，而是顶层Makefile没有添加

Makefile：
```
#添加顶层目录下的子文件夹(注意目录名后面加一个/)
obj-y += display/
```

然后子文件夹下添加相应规则
(子)Makefile
```
obj-y += framebuffer.o
```

**错误2**:

    framebuffer.c: In function 'fb_open':
    framebuffer.c:23: warning: missing braces around initializer
    framebuffer.c:23: warning: (near initialization for 'finfo.id')

程序出错部分：

    struct fb_fix_screeninfo finfo = {0};
    struct fb_var_screeninfo vinfo = {0};
错误发生的原因是没有用大括号明确的区分出初始化数据的归类，

暂时不解决

**错误3**：
> 编译通过，但执行发生段错误，指针出错。通过这一错误进一步加深了对指针的使用

类比外部的int a作为函数形参并能够传出来，要用指针形式

外部的指针作为函数形参并能够传出来，要使用**指针的指针**作为形参类型

如下案例：

程序1：

    void myMalloc(char *s) //我想在函数中分配内存,再返回 
    { 
        s=(char *) malloc(100); 
    } 
    void main() 
    { 
        char *p=NULL; 
        myMalloc(p); //这里的p实际还是NULL,p的值没有改变，为什么？ 
        if(p) free(p); 
    } 

程序2：

    void myMalloc(char **s) //指针的指针，双重指针类型
    { 
        *s=(char *) malloc(100); 
    } 
    void main() 
    { 
        char *p=NULL; 
        myMalloc(&p); //这里的p可以得到正确的值了 
        if(p) free(p); 
    } 

**附**：实际开发中，更喜欢利用结构体指针。因为如果不使用结构体指针，那么函数里面将会有一堆的解引用

利用结构体指针进行`址`传递，从而作为输出型参数
```c
void fb_open(struct framebuffer *fb)//指针
{
    ...
}

void main()
{
    struct framebuffer fb0;
    ...
    fb_open(&fb0);//取地址符&
}
```


**另外**：在C语言中，使用结构体的时候 "->" 和 “." 有什么区别？

    定义的结构体如果是指针，访问成员时就用->
    如果定义的是结构体变量，访问成员时就用.
    例如：
    struct AAA {
        int a;
        char b;
    };
    struct AAA q; 访问成员就用：q.a;
    struct AAA *p; 访问成员就用：p->a;


**另外**：结构体中函数参数可以正在定义的结构体

    struct framebuffer{
    	int fd;
    	unsigned int *pfb;
    	int  (*open)(struct framebuffer *fb);
    	void (*close)(struct framebuffer *fb);
    };

####图片显示及常见功能添加

> 概念：像素 像素间距 物理分辨率 显示分辨率 清晰度

bpp:像素深度，即每个像素用多少bit，常见的24bbp(24位色)RGB888<br>
颜色序:RGB\BGR

先使用Image2Lcd软件获取一幅图片数据：
Image_001.h:
```c
const unsigned char Image_001[1843200] = { /* 0X00,0X18,0X00,0X04,0X58,0X02,0X00,0X1B, */
0X03,0X03,0X05,0X03,0X03,0X05,0X03,0X03,0X05,0X03,0X03,0X05,0X03,0X03,0X05,0X03,
0X03,0X05,0X03,0X03,0X05,0X03,0X03,0X05,...
```
显示图片函数：使用位运算把char组成int

```c
struct draw_info{
	unsigned int *pstar;
	unsigned int width;
	unsigned int height;
	unsigned int color;
	const unsigned char *pic;
};
```
```c
void fb_show_image(struct draw_info *draw_info)
{
	unsigned int *p = draw_info->pstar;
	const unsigned char *img = draw_info->pic;
	
	unsigned int x, y;
	unsigned int cnt ;

	for (y=0; y<draw_info->height; y++)
	{
		for (x=0; x<draw_info->width; x++)
		{
			cnt = (draw_info->width)*y+x;
			cnt*=3;
			*(p + y * WIDTH + x)= ((img[cnt+0] << 16) | (img[cnt+1] << 8) | (img[cnt+2] << 0));//根据显示的颜色序更改
			                         //另外framebuffer地址还是要用屏幕实际分辨率来算
		}
	}
}
```

添加显示任意尺寸图片功能和任意位置显示：

```c
struct draw_info{
	unsigned int *pstar;
	unsigned int x0;
	unsigned int y0;
	unsigned int width;
	unsigned int height;
	unsigned int color;
	const unsigned char *pic;
};
```
```c
void fb_show_image(struct draw_info *draw_info)
{
	unsigned int *p = draw_info->pstar;
	const unsigned char *img = draw_info->pic;
	
	unsigned int x, y;
	unsigned int cnt ;

	for (y=0; (y<draw_info->height)&&(y<HEIGHT); y++)
	{
		for (x=0; (x<draw_info->width)&&(x<WIDTH); x++)
		{
			cnt = (draw_info->width)*y+x;
			cnt*=3;
			*(p + y * WIDTH + x) = ((img[cnt+0] << 16) | (img[cnt+1] << 8) | (img[cnt+2] << 0));
		}
	}
}
```



###2017-02-11

####BMP图片信息分析

> 按照计算一幅1024*600 jpg格式图片所占内存为`1024*600*3/1024/1024`=1.75M,但实际在PC上显示只有几百kb。原因是被压缩了，被压缩是需要付出相应代价的。

BMP：bit map picture 位图格式(未被压缩)<br>
(1)BMP文件组成：头信息(位深度分辨率等)+有效信息<br>
(2)BMP文件如何被识别：(开头为0x42 0x4d)<br>
(3)更详细的介绍：http://blog.csdn.net/zhaozidong86/article/details/6628469
```c
typedef unsigned char BYTE;  
typedef unsigned short WORD;  
typedef unsigned long DWORD;  
typedef long LONG; 

//位图文件头信息结构定义  
//其中不包含文件类型信息（由于结构体的内存结构决定，要是加了的话将不能正确读取文件信息）  
typedef struct tagBITMAPFILEHEADER {  
	//BYTE  bfType[2];			//文件类型，"BM"(0x4D42)
	DWORD bfSize;           	//文件大小  
	WORD  bfReserved1;      	//保留字，不考虑  
	WORD  bfReserved2;      	//保留字，同上  
	DWORD bfOffBits;        	//实际位图数据的偏移字节数，即前三个部分长度之和  
} BITMAPFILEHEADER;

//信息头BITMAPINFOHEADER，也是一个结构，其定义如下：  
typedef struct tagBITMAPINFOHEADER{  
//public:  
	DWORD   biSize;             //指定此结构体的长度，为40  
	LONG    biWidth;            //位图宽  
	LONG    biHeight;           //位图高  
	WORD    biPlanes;           //平面数，为1  
	WORD    biBitCount;         //采用颜色位数，可以是1，2，4，8，16，24，新的可以是32  
	DWORD   biCompression;      //压缩方式，可以是0，1，2，其中0表示不压缩  
	DWORD   biSizeImage;        //实际位图数据占用的字节数  
	LONG    biXPelsPerMeter;    //X方向分辨率  
	LONG    biYPelsPerMeter;    //Y方向分辨率  
	DWORD   biClrUsed;          //使用的颜色数，如果为0，则表示默认值(2^颜色位数)  
	DWORD   biClrImportant;     //重要颜色数，如果为0，则表示所有颜色都是重要的  
} BITMAPINFOHEADER;

//调色板Palette，当然，这里是对那些需要调色板的位图文件而言的。24位和32位是不需要调色板的。  
//（似乎是调色板结构体个数等于使用的颜色数。）  
typedef struct tagRGBQUAD {   
//public:  
	BYTE     rgbBlue; 			//该颜色的蓝色分量  
	BYTE     rgbGreen; 			//该颜色的绿色分量  
	BYTE     rgbRed; 			//该颜色的红色分量  
	BYTE     rgbReserved; 		//保留值  
} RGBQUAD;

typedef struct tagImage
{  
    int width;  
    int height;  
    int channels;  
    unsigned char* imageData;  
}C1Image; 
```

关键数据：宽度和高度，偏移量

####BMP图片的显示(颜色序转变)
第一步打开BMP图片<br>
第二步判断图片格式是否真为BMP<br>
第三步解析头信息，得到该BMP图片的详细信息<br>
第四步根据第三步得到的信息，去合式的位置提取真正的有效图片信息<br>
第五步将得到的有效数据扔到framebuffer中(由于bmp图象是从下至上从从右往左存储的，所以我们不能进行直接顺序读取)


语法注意1：fread后文件指针会发生移动，使用fseek移到想要的位置

语法注意2：注意free


###2017-02-12 

####jpg图片信息分析

> 参考文章：http://www.cnblogs.com/Wendy_Yu/archive/2011/12/27/2303118.html

JPEG/JPG - 文件头标识 (2 bytes): `$ff, $d8 (SOI)` (JPEG 文件标识) - 文件结束标识 (2 bytes): `$ff, $d9 (EOI)`

####jpg图片解码

> jpg图片中的二进制数并不对应像素数据,要显示jpg图片必须先解码jpg得到相应的位图数据

(1)图片编码和解码对应着压缩和解压缩过程<br>
(2)编码和解码其实就是一些数学运算（压缩度、算法复杂度、时间、清晰度）<br>
(3)软件编解码和硬件编解码(数据手册15页JPEG Codec)<br>
(4)不同的图片格式其实就是编解码的算法不同，结果是图片特征不同<br>
(5)编程：使用开源编解码库


#####开源库使用

(1)移植（源码下载、解压、配置、修改Makefile、编译或交叉编译）。

    移植的目的是由源码得到三个东西：动态库.so，静态库.a，头文件.h
(2)部署（部署动态库so、部署静态库.a和头文件.h）

    动态库so文件要放到开发板运行的文件系统中去的（放的过程就叫部署）
(3)注意三个编译链接选项：-I  -l  -L

    -I是编译选项（准确的是说是预处理选项CFLAGS或者CPPFLAGS中指定），用来指定预处理时查找头文件的范围的
    例:    CFLAGS += -I $(shell pwd)/include 
    .
    -l是链接选项（LDFLAGS中指定），用来指定链接额外的库（譬如我们用到了数学函数，就用-lm，链接器就会去链接libm.so
    那么我们使用了libjpeg，对应的库名字就叫libjpeg.so，就需要用-ljpeg选项去链接）
    -L是链接选项（LDFLAGS中指定），用来告诉链接器到哪个路径下面去找动态链接库。
    例：   LDFLAGS := -ljpeg -L/opt/lib-codec/lib
    总结：-l是告诉链接器要链接的动态库的名字，而-L是告诉链接器库的路径(配合使用)
    +-
    注意区分编译链接器需要的动态链接库的路径和使用动态链接时程序运行需要动态链接库的路径

**具体步骤**：

**1.移植**
(1)源码下载、解压
(2)配置   

    ./configure CC=arm-linux-gcc LD=arm-linux-ld --prefix=/opt/lib-codec --exec-prefix=/opt/lib-codec --enable-shared --enable-static -build=i386 -host=arm-linux
    .
    --prefix=  指定编译后的动态库.so，静态库.a，头文件.h存放位置(配置之前确定目录是存在的)
    --exec-prefix= 指定可执行文件存放位置
    --enable-shared=：使能共享，猜测生成动态链接库.so
    --enable-static=：使能静态，猜测生成静态链接库.a和头文件.h
    -build=：编译环境的设置
    -host=：运行环境CPU和系统设置
(3)上面步骤执行完后会生成Makefile文件，检查交叉编译设置是否正确

(4)检查需要的文件夹是否存在(看xxxdir变量)

    bindir = ${exec_prefix}/bin                     
    datarootdir = ${prefix}/share
    includedir = ${prefix}/include
    libdir = ${exec_prefix}/lib
    libexecdir = ${exec_prefix}/libexec
    localstatedir = ${prefix}/var
    sbindir = ${exec_prefix}/sbin
    sharedstatedir = ${prefix}/com
    sysconfdir = ${prefix}/etc
整理一下：

    datarootdir = ${prefix}/share
    includedir = ${prefix}/include
    localstatedir = ${prefix}/var
    sharedstatedir = ${prefix}/com
    sysconfdir = ${prefix}/etc
    .
    bindir = ${exec_prefix}/bin
    libdir = ${exec_prefix}/lib
    libexecdir = ${exec_prefix}/libexec
    sbindir = ${exec_prefix}/sbin
在选定存放的文件夹（lib-codec）下建立`mkdir share include var com etc`文件夹<br>
在选定存放的文件夹（lib-codec）下建立`mkdir bin lib libexec sbin`文件夹<br>
没试过没建立会怎么样，但Makefile 文件中定义了MKDIR_P命令那应该会自己建立

(5)编译	make
(6)安装 make install		

    安装就是将编译生成的库文件、头文件、可执行文件分别装载到--prefix  --exec-prefix所指定的那些目录中去。
    安装完成后如果ubuntu可以用tree命令查看生成的文件树
    
**2.部署**<br>

    部署动态链接库一般有三个位置可以考虑：
    第一个：/lib； 第二个：/usr/lib； 第三个：任意指定目录
    
把动态链接库文件复制到开发板运行的根文件系统的/usr/lib文件夹下，

    cp复制时使用 `-a` 或`-d`选项保留链接。`-a`选项通常在拷贝目录时使用，它保留链接、文件属性，并递归地拷贝目录，
    其作用等于dpR选项的组合
    
**3.程序相应处理**

头文件.h有两种处理方式（静态链接库.a使用这里不作说明）：<br>
第一种：不用动，Makefile里的编译参数`CFLAGS`添加相应的头文件路径

    CFLAGS += -I $(shell pwd)/include -I/opt/lib-codec/include
第二种：放到工程里面——.h放到工程include目录


Makefile文件中添加链接相应路径（就是指明.h文件中声明的函数实体的位置）:

    LDFLAGS := -ljpeg -L/opt/lib-codec/lib


####jpg图片显示

看jpegsrc库源码自带的文档（说明文档和示例代码）：<br>
(1)说明文档：README和libjpeg.txt<br>
(2)示例代码：example.c

程序流程：
(1)图片编码和解码对应着压缩和解压缩过程<br>
(2)编码和解码其实就是一些数学运算（压缩度、算法复杂度、时间、清晰度）<br>
(3)软件编解码和硬件编解码(数据手册15页JPEG Codec)<br>
(4)不同的图片格式其实就是编解码的算法不同，结果是图片特征不同<br>
(5)编程：使用开源编解码库

    put_scanline_someplace要自己写
    
    int read_JPEG_file(char* filename)
    {
        JSAMPARRAY buffer;
        ...
        put_scanline_someplace(buffer[0], row_stride);
    }
    
    void put_scanline_someplace(JSAMPARRAY buffer, int row_stride);这样定义出错
    
    void put_scanline_someplace(JSAMPROW buffer, int row_stride);根据提示修改为JSAMPROW
    正确，因为typedef JSAMPROW *JSAMPARRAY;也只有这样才能真正传进数据的地址
    


####总结：遇到问题去库源码中找解决办法

遇到问题不着急，逻辑分析函数，慢慢分析总比干着急好

在合适的地方打印信息

进入库目录，使用`grep "要搜索的函数" * -nR`


###2017-02-13 

####png图片信息分析
> png和jpg都是压缩格式的图片，都是二进制文件，不同之处是压缩和解压缩的算法不同

####png图片解码

#####libpng移植

移植步骤：

(1)下载源码包：<br>
(2)解压、配置、修改Makefile、编译、部署

    ./configure CC=arm-linux-gcc LD=arm-linux-ld --prefix=/opt/lib-codec --exec-prefix=/opt/lib-codec --enable-shared --enable-static -build=i386 -host=arm-linux
(3)配置出错，报错信息：`configure: error: zlib not installed`
分析问题是因为libpng依赖于zlib库，所以要先移植zlib库才可以<br>
(4)移植了zlib后再过来配置，还是报错，原因是因为没有导出相关环境变量，所以libpng在配置的时候找不到刚才移植的zlib库的库文件和头文件<br>
(5)解决方案就是使用epport临时性的导出

    # export LDFLAGS="-L/opt/lib-codec/lib"
    # export CFLAGS="-I/opt/lib-codec/include"
    # export CPPFLAGS="-I/opt/lib-codec/include"

(6)导出后再次配置就过了，然后编译和安装<br>
(7)make && make install


zlib移植:

(1)下载`：http://www.zlib.net/`，并解压<br>
(2)配置：

    export CC=arm-linux-gcc      
    ./configure -shared --prefix=/opt/lib-codec
(3)make && make install<br>
(4)make install后/opt/libdecode目录下的lib和include目录下就有了zlib的静态库动态库和头文件，然后回去继续libpng的移植



####png图片显示

> 参考网络博客

错误1：c1png.c:112: error: dereferencing pointer to incomplete type

移植好的png库的头文件没有全部放进opt/lib=codec/include(坑爹呢这是)



###2017-02-14


####图片管理


1.图片文件的管理

(1)在物理磁盘存储层次上：用一个文件夹来管理；在程序中，用数据结构来管理<br>
(2)用数组管理<br>
(3)用链表管理<br>


2.图片信息的自动检索

(1)读取文件类型<br>
(2)普通文件和文件夹分类处理<br>
(3)普通文件区分，将其中的图片按格式存储到图片管理数组/链表中<br>



####程序整理

模块化编程

封装出对外接口

###2017-2-15


####触摸翻页-触摸屏基本操作代码

主要是对struct input_event 结构体的解析


###总结 

收获最大的是编程能力的进一步提高以及如何使用一些开源库

特别是对结构体指针的是使用有了进一步的认识

模块化编程-如何合理设计形参以及封装对外接口



**项目简单介绍**

项目主要是利用linux API操作帧缓冲进行图片的显示；编写Makefile进行程序的编译和链接；

移植libjpeg库和libpng库，阅读文档看示例代码对图片进行解码；实现图片管理和触摸翻页 | 模块化编程


**库的移植**

主要是配置选项为：指定编译工具和链接工具，指定安装目录，指定编译环境，指定将来要运行的CPU类型和系统OS

（有时没有编译工具和链接声明选项，可以使用export临时性导出）

**图片显示原理**

开打framebuffer设备文件得到文件节点fd，然后进行地址映射得到指针，将来要显示图片就直接往指针指向的地址安放数据（一个像素占4个字节）

图片数据的结构分为头信息和数据部分，利用库提供的接口对数据部分进行解码

按照RGB888的格式解码后的数据，用位移的方式，安放到帧缓冲映射到虚拟地址空间的内存中去


**触摸翻页如何实现**

打开触摸屏对应的设备文件，定义一个input event结构体变量接收触摸事件，通过解析结构体变量判断是否为一次触摸事件，获取触摸点的坐标进行翻页。

（当硬件发生相应动作时input子系统会将事件打包成一个input event结构体变量）


**开发时遇到的问题以及如何解决**：

按照源码提供的示例代码进行jpeg图片解码的时候，示例程序有一个函数在库的源码中没有，一开始猜测是不是有头文件没有添加进来，但是在linux下用grep搜索命令没找到。也就是这个函数需要自己实现，然后根据对解码的整个过程的理解尝试着进行添加。

程序运行正常但图片不能正常显示，把解码后的数据直接打印出来发现解码出来的数据是错误的(都是000)。仔细阅读代码配合网上的博客，根据理解然后还到源码中看函数原型，把一个函数直接用自己的简单函数替代然后就可以了

另外还有就是编译成功但是运行段错误，没正确使用结构体指针，解决问题后对问题进行了进一步扩展，归纳了结构体指针的可能用法，写了一篇博客。








